{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local')\n",
    "         .appName('06_remove-column')\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Set dynamic partitions to overwrite only the partition processed\n",
    "spark.conf.set('spark.sql.sources.partitionOverwriteMode', 'dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimesis import Person, Address\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, DateType, FloatType\n",
    "\n",
    "def gen_data_remove_column(data_path, partition_date, num_rows):\n",
    "    person = Person('en')\n",
    "    address = Address('en')\n",
    "    \n",
    "    schema_street = StructType(\n",
    "        [\n",
    "            StructField('street_name', StringType(), True)\n",
    "            # StructField('lat', FloatType(), True), #column removed\n",
    "            # StructField('long', FloatType(), True) #column removed\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    schema_address_details = StructType(\n",
    "        [\n",
    "            StructField('street', schema_street, True),\n",
    "            StructField('number', IntegerType(), True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    schema_address = StructType(\n",
    "        [\n",
    "            StructField('address_details', schema_address_details, True),\n",
    "            StructField('city', StringType(), True),\n",
    "            StructField('country', StringType(), True),\n",
    "            # StructField('country_code', StringType(), True), #column removed\n",
    "            StructField('state', StringType(), True),\n",
    "            StructField('postal_code', IntegerType(), True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    schema_df = StructType(\n",
    "        [\n",
    "            StructField('identifier', StringType(), True),\n",
    "            StructField('first_name', StringType(), True),\n",
    "            StructField('last_name', StringType(), True),\n",
    "            StructField('occupation', StringType(), True),\n",
    "            StructField('age', IntegerType(), True),\n",
    "            StructField('address', schema_address, True),\n",
    "            # StructField('title_name', StringType(), True), #column removed\n",
    "            StructField('date', DateType(), True)\n",
    "\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        df_temp = spark.createDataFrame([\n",
    "            [\n",
    "                person.identifier(),\n",
    "                person.first_name(),\n",
    "                person.last_name(),\n",
    "                person.occupation(),\n",
    "                person.age(),\n",
    "                [\n",
    "                    [\n",
    "                        [\n",
    "                            address.street_name()\n",
    "                            #float(address.latitude()),\n",
    "                            #float(address.longitude())\n",
    "                        ],\n",
    "                        int(address.street_number())\n",
    "                    ],\n",
    "                    address.city(),\n",
    "                    address.country(),\n",
    "                    #address.country_code(),\n",
    "                    address.state(),\n",
    "                    int(address.postal_code())\n",
    "                ],\n",
    "                #person.title(),\n",
    "                partition_date\n",
    "            ]\n",
    "        ], schema_df)\n",
    "\n",
    "        try:\n",
    "            df = df.union(df_temp)\n",
    "        except:\n",
    "            df = df_temp\n",
    "            \n",
    "    df.coalesce(1).write.partitionBy('date').mode('overwrite').parquet(data_path)\n",
    "    \n",
    "    print('Partition created: {data_path}/date={date}'.format(data_path=data_path,date=partition_date))\n",
    "    print('# Rows:',df.count())\n",
    "    print('Schema:')\n",
    "    df.printSchema()\n",
    "    print('\\n')\n",
    "    \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
